[0m[[0m[0mdebug[0m] [0m[0m> Exec(collectAnalyses, None, Some(CommandSource(network-1)))[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Processing event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / collectAnalyses[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: Signal, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: initialized: JsonRpcNotificationMessage(2.0, initialized, {})[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///home/trungdq/StreamHandler/src/main/scala/StreamHandler.scala","languageId":"scala","version":1,"text":"import org.apache.spark.sql._\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.streaming._\nimport org.apache.spark.sql.types._\n\nobject StreamHandler {\n    def main(args: Array[String]) {\n        val spark = SparkSession\n            .builder\n            .appName(\"Stream Handler\")\n            .getOrCreate()\n\n        spark.sparkContext.setLogLevel(\"ERROR\")\n\n        import spark.implicits._\n\n        val inputOrderDF = spark\n            .readStream\n            .format(\"kafka\")\n            .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n            .option(\"subscribe\", \"orders\")\n            .load()\n\n        // FOR orders\n        /*\n            {\"id\":null,\"customerId\":1,\"orderTime\":\"2022-12-27\",\"shippingCost\":60000,\n            \"subtotal\":99280000,\"total\":99340000,\"deliverDays\":6,\n            \"deliverDate\":\"2023-01-02\",\"paymentMethod\":\"COD\",\n            \"shippingAddress\":\"Receiver: Trung Dang. Address: BCON Suoi Tien, Di An, Binh Duong. Phone Number: 0359904878\"}\n        */\n\n        val orderSchema = new StructType()\n                .add(\"id\", StringType)\n                .add(\"customerId\", LongType)\n                .add(\"orderTime\", DateType)\n                .add(\"shippingCost\", FloatType)\n                .add(\"subtotal\", FloatType)\n                .add(\"total\", FloatType)\n                .add(\"deliverDays\", IntegerType)\n                .add(\"deliverDate\", DateType)\n                .add(\"paymentMethod\", StringType)\n                .add(\"shippingAddress\", StringType)\n\n        val rawOrderDF = inputOrderDF.selectExpr(\"CAST(value AS STRING)\")\n    \n        // col(\"value\") => data from kafka\n        val ordersDF = rawOrderDF.select(from_json(col(\"value\"), orderSchema).as(\"data\"))\n                            .select(\"data.*\")\n\n        val orderSummary = ordersDF.withColumnRenamed(\"customerId\", \"customer_id\")\n            .withColumnRenamed(\"orderTime\", \"order_time\")\n            .withColumnRenamed(\"shippingCost\", \"shipping_cost\")\n            .withColumnRenamed(\"deliverDays\", \"deliver_days\")\n            .withColumnRenamed(\"deliverDate\", \"deliver_date\")\n            .withColumnRenamed(\"paymentMethod\", \"payment_method\")\n            .withColumnRenamed(\"shippingAddress\", \"shipping_address\")\n\n        val orderQuery = orderSummary\n            .writeStream\n            .foreachBatch { (batchDF: DataFrame, batchID: Long) =>\n                println(s\"Order Writing to MySQL $batchID\")\n                batchDF.write\n                    .mode(\"append\")\n                    .format(\"jdbc\")\n                    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n                    .option(\"url\", \"jdbc:mysql://20.239.84.62:3306/ecommerce\")\n                    .option(\"dbtable\", \"orders\")\n                    .option(\"user\", \"admin\")\n                    .option(\"password\", \"pAssWoRd@2022haCkerLord\")\n                    .save()\n            }\n            .outputMode(\"update\")\n            .start()\n\n        val inputOrderDetailDF = spark\n            .readStream\n            .format(\"kafka\")\n            .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n            .option(\"subscribe\", \"order-detail\")\n            .load()\n        // FOR order-detail\n        /*\n            {\"quantity\":2,\"shippingCost\":60000,\"unitPrice\":30390000,\"subtotal\":60780000,\"productId\":2,\"orderId\":null}\n        */\n\n        val orderDeDetailSchema = new StructType()\n                .add(\"quantity\", IntegerType)\n                .add(\"shippingCost\", FloatType)\n                .add(\"unitPrice\", FloatType)\n                .add(\"subtotal\", FloatType)\n                .add(\"productId\", LongType)\n                .add(\"orderId\", StringType)\n\n        val rawOrderDetailDF = inputOrderDetailDF.selectExpr(\"CAST(value AS STRING)\")\n\n        val orderDetailDF = rawOrderDetailDF.select(from_json(col(\"value\"), orderDeDetailSchema).as(\"data\"))\n                        .select(\"data.*\")\n\n        val orderDetailSummary = orderDetailDF.withColumnRenamed(\"productId\", \"product_id\")\n            .withColumnRenamed(\"orderId\", \"order_id\")\n            .withColumnRenamed(\"shippingCost\", \"shipping_cost\")\n            .withColumnRenamed(\"unitPrice\", \"unit_price\")\n\n        val orderDetailQuery = orderDetailSummary\n            .writeStream\n            .foreachBatch { (batchDF: DataFrame, batchID: Long) =>\n                println(s\"OrderDetail Writing to MySQL $batchID\")\n                batchDF.write\n                    .mode(\"append\")\n                    .format(\"jdbc\")\n                    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n                    .option(\"url\", \"jdbc:mysql://20.239.84.62:3306/ecommerce\")\n                    .option(\"dbtable\", \"order_detail\")\n                    .option(\"user\", \"admin\")\n                    .option(\"password\", \"pAssWoRd@2022haCkerLord\")\n                    .save()\n            }\n            .outputMode(\"update\")\n            .start()\n        \n        orderQuery.awaitTermination()\n        orderDetailQuery.awaitTermination()\n    }\n}"}})[0m
[0m[[0m[0mdebug[0m] [0m[0manalysis location (/home/trungdq/StreamHandler/target/scala-2.12/zinc/inc_compile_2.12.zip,true)[0m
[0m[[0m[32msuccess[0m] [0m[0mTotal time: 1 s, completed Dec 27, 2022 3:27:06 PM[0m
[0m[[0m[0mdebug[0m] [0m[0munmatched Done event for requestId None: None[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
[0m[[0m[0mdebug[0m] [0m[0mUnhandled notification received: textDocument/didOpen: JsonRpcNotificationMessage(2.0, textDocument/didOpen, {"textDocument":{"uri":"file:///home/trungdq/StreamHandler/build.sbt","languageId":"scala","version":1,"text":"name := \"Stream Handler\"\n\nversion := \"1.0\"\n\nscalaVersion := \"2.12.15\"\n\nlibraryDependencies ++= Seq (\n    \"org.apache.spark\" %% \"spark-core\" % \"3.3.1\" % \"provided\",\n    \"org.apache.spark\" %% \"spark-sql\" % \"3.3.1\" % \"provided\",\n    \"mysql\" % \"mysql-connector-java\" % \"8.0.28\"\n)"}})[0m
[0m[[0m[0mdebug[0m] [0m[0mForcing garbage collection...[0m
